# type: ignore
import sys


# The hacky indexing on types isn't possible with python < 3.9
if sys.version_info[:2] < (3, 9):
    raise EnvironmentError("schema generation requires python 3.8 or higher")

import json
import re
from pathlib import Path
from typing import Any, Dict, Optional, Type, Tuple

from pydantic import BaseConfig, BaseModel, Field, create_model
from pydantic.fields import FieldInfo
from typing import Annotated
from typing_extensions import (
    NotRequired,
    _TypedDictMeta,
    get_args,
    get_origin,
)
from event_model.documents.generate.type_wrapper import AsRef

from event_model import SCHEMA_PATH
from event_model.documents import (
    Datum,
    DatumPage,
    Event,
    EventDescriptor,
    EventPage,
    Resource,
    RunStart,
    RunStop,
    StreamDatum,
    StreamResource,
)
from event_model.documents.generate.type_wrapper import (
    extra_schema,
    ALLOWED_ANNOTATION_ELEMENTS,
)

SCHEMA_OUT_DIR = Path("event_model") / SCHEMA_PATH


# Used to add user written schema to autogenerated schema.
def merge_dicts(dict1: dict, dict2: dict) -> dict:
    """
    Takes two dictionaries with subdirectories and returns a new dictionary of the two merged:
    dict1 = {
        "x1": {
            "y1": 0,  "y3": {"z1" : [1, 2], "z2": 1}
        },
        "x2" : 0,
        "x3": 1
    }
    and
    dict2 = {
        "x1": {
            "y2" : 0,  "y3": {"z1": [3, 4], "z3": 5}
        },
        "x3" : 0
    }
    returns
    {
        "x1": {
            "y1": 0, "y2": 0,  "y3": {"z1": [1, 2, 3, 4], "z2": 1, "z3": 5}
        },
        "x2": 0
        "x3": 1
    }
    """

    return_dict = dict2.copy()

    for key in dict1:
        if key not in dict2:
            return_dict[key] = dict1[key]

        elif not isinstance(dict1[key], type(dict2[key])):
            return_dict[key] = dict1[key]

        elif isinstance(dict1[key], dict):
            return_dict[key] = merge_dicts(dict1[key], dict2[key])

        elif isinstance(dict1[key], list):
            return_dict[key] = dict1[key] + dict2[key]

    return return_dict


def format_all_annotations(typed_dict: _TypedDictMeta):
    """
    Goes through all fields type_annotations and formats them to be acceptable
    to pydantic:

    * NotRequired[Annotated[X, FieldInfo, ...] -> Annotated[Optional[X],
      FieldInfo, ...]
    * Annotated[X, AsRef("ref_name"), FieldInfo] -> Annotated[ref_name_class_containing_X,
      FieldInfo]
    * If X is also a typeddict then Annotated[X, FieldInfo] -> Annotated[format_all_annotations(X), FieldInfo]

    """
    new_annotations = {}
    new_basemodel_classes = {}

    for name, field in typed_dict.__annotations__.items():
        new_annotations[name] = field_parser(name, field, new_basemodel_classes)

    typed_dict.__annotations__ = new_annotations

    return typed_dict


def field_is_annotated(field: type):
    return get_origin(field) == Annotated


def field_is_not_required(field: type, remove_origin_if_NotRequired=False):
    is_not_required = get_origin(field) == NotRequired
    if is_not_required and remove_origin_if_NotRequired:
        args = get_args(field)
        assert len(args) == 1
        field = args[0]
    return field, is_not_required


def get_field_type(
    name: str, field: type, is_not_required: bool, is_annotated: bool
) -> type:
    origin = get_origin(field)
    args = get_args(field)
    if not is_not_required and not is_annotated:
        field_type = origin
    else:
        field_type = [
            x
            for x in args
            if True not in [isinstance(x, y) for y in ALLOWED_ANNOTATION_ELEMENTS]
        ]
        assert (
            len(field_type) == 1
        ), f'Field "{name}") has multiple types: {" and ".join(field_type)}'
        field_type = field_type[0]

    if isinstance(field_type, _TypedDictMeta):
        field_type = format_all_annotations(field_type)

    return field_type


def get_annotation_contents(args: Tuple[type, ...]) -> Tuple[AsRef, FieldInfo]:
    as_ref = None
    field_info = None
    if args:
        for arg in args:
            if isinstance(arg, AsRef):
                as_ref = arg
            elif isinstance(arg, FieldInfo):
                field_info = arg

    field_info = field_info or Field()

    return as_ref, field_info


def parse_AsRef(field_type, field_info, as_ref, new_basemodel_classes):
    ref_field_info = Field()
    if field_info.regex:
        ref_field_info.regex = field_info.regex
    ref_field_type = Annotated[field_type, ref_field_info]

    if as_ref.ref_name not in new_basemodel_classes:
        new_field_type = create_model(
            as_ref.ref_name,
            __config__=Config,
            __root__=(ref_field_type, None),
        )
        new_basemodel_classes[as_ref.ref_name] = new_field_type
        field_type = new_field_type
    else:
        generated_basemodel_type = new_basemodel_classes[
            as_ref.ref_name
        ].__annotations__["__root__"]
        assert get_args(ref_field_type)[0] == get_args(generated_basemodel_type)[0], (
            f'Fields with type AsRef("{as_ref.ref_name}") have differing types: '
            f"{generated_basemodel_type} and {ref_field_type}"
        )
        field_type = new_basemodel_classes[as_ref.ref_name]

    return field_type


def field_parser(name: str, field: type, new_basemodel_classes: Dict[str, BaseModel]):
    # Change the field from NotRequired[X] to X
    field, is_not_required = field_is_not_required(
        field, remove_origin_if_NotRequired=True
    )

    is_annotated = field_is_annotated(field)

    field_type = get_field_type(name, field, is_not_required, is_annotated)

    as_ref, field_info = get_annotation_contents(get_args(field))

    if as_ref:
        field_type = parse_AsRef(field_type, field_info, as_ref, new_basemodel_classes)
        field_info.regex = None

    if is_not_required:
        field_type = Optional[field_type]

    return Annotated[field_type, field_info]


class Config(BaseConfig):
    """
    Config for generated BaseModel.
    """

    # extra = Extra.forbid

    def alias_generator(string_to_be_aliased):
        """
        Alias in snake case
        """
        return re.sub(r"(?<!^)(?=[A-Z])", "_", string_to_be_aliased).lower()


# From https://github.com/pydantic/pydantic/issues/760#issuecomment-589708485
def parse_typeddict_to_schema(
    typed_dict: Any,
    out_dir: Optional[Path] = None,
) -> Type[BaseModel]:
    annotations: Dict[str, Any] = {}

    typed_dict = format_all_annotations(typed_dict)

    for name, field in typed_dict.__annotations__.items():
        default_value = getattr(typed_dict, name, ...)
        annotations[name] = (field, default_value)

    model = create_model(typed_dict.__name__, __config__=Config, **annotations)

    # Docstring is used as the description field.
    model.__doc__ = typed_dict.__doc__

    # title goes to snake_case
    model.__name__ = Config.alias_generator(typed_dict.__name__).lower()
    model_schema = model.schema(by_alias=True)

    model_schema["description"] = typed_dict.__doc__

    # Add the manually defined extra stuff
    if typed_dict in extra_schema:
        model_schema = merge_dicts(extra_schema[typed_dict], model_schema)

    if out_dir:
        with open(out_dir / f'{model_schema["title"]}.json', "w+") as f:
            json.dump(model_schema, f, indent=3)

    return model_schema


def generate_all_schema(schema_out_dir: Path = SCHEMA_OUT_DIR) -> None:
    parse_typeddict_to_schema(DatumPage, out_dir=schema_out_dir)
    parse_typeddict_to_schema(Datum, out_dir=schema_out_dir)
    parse_typeddict_to_schema(EventDescriptor, out_dir=schema_out_dir)
    parse_typeddict_to_schema(EventPage, out_dir=schema_out_dir)
    parse_typeddict_to_schema(Event, out_dir=schema_out_dir)
    parse_typeddict_to_schema(Resource, out_dir=schema_out_dir)
    parse_typeddict_to_schema(RunStart, out_dir=schema_out_dir)
    parse_typeddict_to_schema(RunStop, out_dir=schema_out_dir)
    parse_typeddict_to_schema(StreamDatum, out_dir=schema_out_dir)
    parse_typeddict_to_schema(StreamResource, out_dir=schema_out_dir)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--schema_out_directory", default=SCHEMA_OUT_DIR, nargs="?")
    args = parser.parse_args()
    generate_all_schema(schema_out_dir=args.schema_out_directory)
